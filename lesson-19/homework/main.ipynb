{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4333116c",
   "metadata": {},
   "source": [
    "You are given a dataset containing sales data for an e-commerce website. The dataset (task\\sales_data.csv) has the following columns:\n",
    "\n",
    "Date: Date of the sale.\n",
    "Product: Name of the product sold.\n",
    "Category: Category to which the product belongs.\n",
    "Quantity: Number of units sold.\n",
    "Price: Price per unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87427e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate stats by category:\n",
      "   Category  total_quantity  average_price  max_quantity_per_transaction\n",
      "   Clothing             157      31.176471                            15\n",
      "Electronics             183     276.764706                            15\n",
      "       Home             144      55.000000                            14\n",
      "\n",
      "Top‐selling product by category:\n",
      "   Category top_selling_product  total_quantity_sold\n",
      "   Clothing               Jeans                   15\n",
      "Electronics            Smart TV                   15\n",
      "       Home     Pressure Cooker                   14\n",
      "\n",
      "Date with highest total sales:\n",
      "  2023-01-07 — Total Sales = $15150.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv('sales_data.csv', parse_dates=['Date'])\n",
    "\n",
    "# 2. Aggregate stats per Category\n",
    "agg_category = df.groupby('Category').agg(\n",
    "    total_quantity=('Quantity', 'sum'),\n",
    "    average_price=('Price', 'mean'),\n",
    "    max_quantity_per_transaction=('Quantity', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Aggregate stats by category:\")\n",
    "print(agg_category.to_string(index=False))\n",
    "\n",
    "\n",
    "# 3. Top‐selling product per category\n",
    "prod_totals = (\n",
    "    df.groupby(['Category', 'Product'])['Quantity']\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "top_products = (\n",
    "    prod_totals.sort_values(['Category', 'Quantity'], ascending=[True, False])\n",
    "               .groupby('Category')\n",
    "               .first()\n",
    "               .reset_index()\n",
    "               .rename(columns={\n",
    "                   'Product': 'top_selling_product',\n",
    "                   'Quantity': 'total_quantity_sold'\n",
    "               })\n",
    ")\n",
    "\n",
    "print(\"\\nTop‐selling product by category:\")\n",
    "print(top_products.to_string(index=False))\n",
    "\n",
    "\n",
    "# 4. Date with highest total sales\n",
    "df['Sales'] = df['Quantity'] * df['Price']\n",
    "daily_sales = df.groupby('Date')['Sales'].sum().reset_index()\n",
    "top_day = daily_sales.loc[daily_sales['Sales'].idxmax()]\n",
    "\n",
    "print(f\"\\nDate with highest total sales:\")\n",
    "print(f\"  {top_day['Date'].date()} — Total Sales = ${top_day['Sales']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81d6a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers with ≥20 orders:\n",
      "   CustomerID  order_count\n",
      "0         101           21\n",
      "1         102           21\n",
      "2         103           20\n",
      "3         104           20\n",
      "\n",
      "Customers with average unit price > $120:\n",
      "   CustomerID  avg_price_per_unit\n",
      "1         102          138.095238\n",
      "3         104          169.750000\n",
      "\n",
      "Products with total quantity ≥5:\n",
      "             Product  total_quantity  total_price\n",
      "5        Cargo Pants               6          180\n",
      "15       Dress Shirt               5          125\n",
      "19      Formal Shirt               6          210\n",
      "30        Smartphone               5         2000\n",
      "32       Sport Shoes               5          200\n",
      "35        Sunglasses               5           75\n",
      "41  Wireless Earbuds               6          720\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('customer_orders.csv')  # adjust path if needed\n",
    "\n",
    "# 1. Customers with at least 20 orders\n",
    "order_counts = (\n",
    "    df.groupby('CustomerID')\n",
    "      .size()\n",
    "      .reset_index(name='order_count')\n",
    ")\n",
    "customers_20_plus = order_counts[order_counts['order_count'] >= 20]\n",
    "print(\"Customers with ≥20 orders:\")\n",
    "print(customers_20_plus)\n",
    "\n",
    "# 2. Customers with average price per unit > $120\n",
    "avg_price = (\n",
    "    df.groupby('CustomerID')['Price']\n",
    "      .mean()\n",
    "      .reset_index(name='avg_price_per_unit')\n",
    ")\n",
    "customers_avg_gt_120 = avg_price[avg_price['avg_price_per_unit'] > 120]\n",
    "print(\"\\nCustomers with average unit price > $120:\")\n",
    "print(customers_avg_gt_120)\n",
    "\n",
    "# 3. Product totals, filtering out total quantity < 5\n",
    "df['TotalPrice'] = df['Quantity'] * df['Price']\n",
    "product_stats = (\n",
    "    df.groupby('Product')\n",
    "      .agg(\n",
    "          total_quantity=('Quantity', 'sum'),\n",
    "          total_price=('TotalPrice', 'sum')\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "products_qty_5_plus = product_stats[product_stats['total_quantity'] >= 5]\n",
    "print(\"\\nProducts with total quantity ≥5:\")\n",
    "print(products_qty_5_plus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800327be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Lower Bound'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Lower Bound'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     12\u001b[39m bands_df = pd.read_excel(\u001b[33m'\u001b[39m\u001b[33mpopulation_salary_analysis.xlsx\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 3. Assign each person to a band\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#    Assume bands_df has columns ['BandName', 'MinSalary', 'MaxSalary']\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#    We'll do a merge‑like assignment via pandas interval mapping\u001b[39;00m\n\u001b[32m     17\u001b[39m bands_df[\u001b[33m'\u001b[39m\u001b[33minterval\u001b[39m\u001b[33m'\u001b[39m] = pd.IntervalIndex.from_arrays(\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mbands_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLower Bound\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bands_df[\u001b[33m'\u001b[39m\u001b[33mUpper Bound\u001b[39m\u001b[33m'\u001b[39m], closed=\u001b[33m'\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Create a categorical Series mapping each salary into the right interval\u001b[39;00m\n\u001b[32m     21\u001b[39m pop_df[\u001b[33m'\u001b[39m\u001b[33mBand\u001b[39m\u001b[33m'\u001b[39m] = pd.cut(\n\u001b[32m     22\u001b[39m     pop_df[\u001b[33m'\u001b[39m\u001b[33mSalary\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     23\u001b[39m     bins=bands_df[\u001b[33m'\u001b[39m\u001b[33minterval\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     24\u001b[39m     labels=bands_df[\u001b[33m'\u001b[39m\u001b[33mBandName\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Lower Bound'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# 1. Load population table via SQL\n",
    "conn = sqlite3.connect('population.db')\n",
    "# assuming table is named 'population' with columns at least ['PersonID','State','Salary']\n",
    "pop_df = pd.read_sql_query(\"SELECT * FROM population\", conn)\n",
    "conn.close()\n",
    "\n",
    "# 2. Load salary bands from Excel\n",
    "bands_df = pd.read_excel('population_salary_analysis.xlsx')\n",
    "\n",
    "# 3. Assign each person to a band\n",
    "#    Assume bands_df has columns ['BandName', 'MinSalary', 'MaxSalary']\n",
    "#    We'll do a merge‑like assignment via pandas interval mapping\n",
    "bands_df['interval'] = pd.IntervalIndex.from_arrays(\n",
    "    bands_df['Lower Bound'], bands_df['Upper Bound'], closed='both'\n",
    ")\n",
    "# Create a categorical Series mapping each salary into the right interval\n",
    "pop_df['Band'] = pd.cut(\n",
    "    pop_df['Salary'],\n",
    "    bins=bands_df['interval'],\n",
    "    labels=bands_df['BandName']\n",
    ")\n",
    "\n",
    "# 4A. Overall statistics per Band\n",
    "total_pop = len(pop_df)\n",
    "\n",
    "overall = pop_df.groupby('Band')['Salary'].agg(\n",
    "    count='size',\n",
    "    average_salary='mean',\n",
    "    median_salary='median'\n",
    ").reset_index()\n",
    "overall['percentage'] = overall['count'] / total_pop * 100\n",
    "\n",
    "print(\"=== Overall by Salary Band ===\")\n",
    "print(overall[['Band', 'percentage', 'average_salary', 'median_salary', 'count']])\n",
    "\n",
    "# 4B. Same measures, broken out by State and Band\n",
    "by_state = (\n",
    "    pop_df\n",
    "    .groupby(['State', 'Band'])['Salary']\n",
    "    .agg(\n",
    "        count='size',\n",
    "        average_salary='mean',\n",
    "        median_salary='median'\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute total population per State for percentage calculation\n",
    "state_totals = pop_df.groupby('State').size().reset_index(name='state_total')\n",
    "\n",
    "by_state = by_state.merge(state_totals, on='State')\n",
    "by_state['percentage'] = by_state['count'] / by_state['state_total'] * 100\n",
    "\n",
    "print(\"\\n=== By State and Salary Band ===\")\n",
    "print(by_state[['State', 'Band', 'percentage', 'average_salary', 'median_salary', 'count']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
